{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MichelNivard/3-causal-sem-models/blob/main/Identification_of_causal_effects_through_heteroskedasticity_in_a_multi_group_SEM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lXp7mZtYyAM7"
      },
      "source": [
        "# Identification through heterokedasticity in a multi-group SEM\n",
        "\n",
        "This is an interactive ilustration of a model that is part of a [github repo](https://github.com/MichelNivard/3-causal-sem-models) and pre-print on three ways to perform causal inference in psychological sciences. Each of these identifies **(cyclical) networks** and **latent variable** models and allows for their direct emperical comparison.\n",
        "\n",
        "Please begin by reading the repo and pre-print as this is not meant for consumption without context.\n",
        "\n",
        "In the model below we identify a causal network trough mult-group SEM. In the multi group SEM we constrain error and confounding in a way that allows us to estimate a (cyclical) network that is identical across groups."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "e4fHm15DuyLN",
        "outputId": "a40df81b-05b6-4988-fff1-1832104d93b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "Warning message in install.packages(\"lavaan\"):\n",
            "“installation of package ‘lavaan’ had non-zero exit status”\n",
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "also installing the dependencies ‘checkmate’, ‘htmlwidgets’, ‘gridExtra’, ‘htmlTable’, ‘viridis’, ‘Formula’, ‘psych’, ‘plyr’, ‘Hmisc’, ‘igraph’, ‘jpeg’, ‘png’, ‘corpcor’, ‘reshape2’, ‘glasso’, ‘fdrtool’, ‘gtools’, ‘pbapply’, ‘abind’\n",
            "\n",
            "\n",
            "Warning message in install.packages(\"qgraph\"):\n",
            "“installation of package ‘checkmate’ had non-zero exit status”\n",
            "Warning message in install.packages(\"qgraph\"):\n",
            "“installation of package ‘htmlwidgets’ had non-zero exit status”\n",
            "Warning message in install.packages(\"qgraph\"):\n",
            "“installation of package ‘psych’ had non-zero exit status”\n",
            "Warning message in install.packages(\"qgraph\"):\n",
            "“installation of package ‘plyr’ had non-zero exit status”\n"
          ]
        }
      ],
      "source": [
        "install.packages(\"lavaan\")\n",
        "install.packages(\"qgraph\")\n",
        "library(lavaan)\n",
        "library(qgraph)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Simulations\n",
        "\n",
        "\n",
        "We simulate 10 groups, each with a sample size of 5000 and in each group we redraw new exogeneous variance in the 5 endogeneous variables (variables of interest).\n",
        "\n",
        "we then simulate network data, add a confounder (`fc`) and per indicator measurement error. We simulate a network (the same one we use in the paper), that gives rise to 5 correlated variables, the correlations etween these avriables are relatively homogeneous (between 0.52 and 0.65) and if these where psychometric tests people could very reasonably impose or assume a latent variable model where one unobserved factor causes the correlated responses on the five variables. \n"
      ],
      "metadata": {
        "id": "2Xh2rjZYiV-b"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y4LNCPiIvaru"
      },
      "outputs": [],
      "source": [
        "set.seed(123)\n",
        "\n",
        "\n",
        "n = 5000\n",
        "groups = 10\n",
        "\n",
        "b <- matrix(c(   0,  .22,   0,  .24,  .35, \n",
        "                 0,   0,   .15,  .31,  .0,\n",
        "                 .35,  .2,   0, -.14,   .3,\n",
        "                 .14, -.2,  .36,   0,   .4,\n",
        "                 0, .30, .15,   -.15,    0), 5,5,byrow=T)\n",
        "\n",
        "\n",
        "\n",
        "for(i in 1:groups){\n",
        "  \n",
        "  if(i == 1){\n",
        "    \n",
        "    \n",
        "    r1 <- rnorm(n,mean = 0,sd = runif(1,min = .8,max = 1.3))\n",
        "    r2 <- rnorm(n,mean = 0,sd = runif(1,min = .8,max = 1.3))\n",
        "    r3 <- rnorm(n,mean = 0,sd = runif(1,min = .8,max = 1.3))\n",
        "    r4 <- rnorm(n,mean = 0,sd = runif(1,min = .8,max = 1.3))\n",
        "    r5 <- rnorm(n,mean = 0,sd = runif(1,min = .8,max = 1.3))\n",
        "    \n",
        "    \n",
        "    x <- cbind(r1,r2,r3,r4,r5)\n",
        "    data <- cbind(i,t(solve(diag(ncol(b))-b) %*% t(x)))\n",
        "    \n",
        "  }\n",
        "  if(i != 1){\n",
        "    \n",
        "    \n",
        "    \n",
        "    r1 <- rnorm(n,mean = 0,sd = runif(1,min = .8,max = 1.3))\n",
        "    r2 <- rnorm(n,mean = 0,sd = runif(1,min = .8,max = 1.3))\n",
        "    r3 <- rnorm(n,mean = 0,sd = runif(1,min = .8,max = 1.3))\n",
        "    r4 <- rnorm(n,mean = 0,sd = runif(1,min = .8,max = 1.3))\n",
        "    r5 <- rnorm(n,mean = 0,sd = runif(1,min = .8,max = 1.3))\n",
        "    \n",
        "    \n",
        "    \n",
        "    x <- cbind(r1,r2,r3,r4,r5)\n",
        "    temp <- cbind(i,t(solve(diag(ncol(b))-b) %*% t(x)))\n",
        "    data <- rbind(data,temp)\n",
        "    \n",
        "    \n",
        "  }\n",
        "  \n",
        "}\n",
        "\n",
        "fc <-  rnorm(n*groups)\n",
        "data[,2] <-  data[,2] +  rnorm(n*groups) + fc\n",
        "data[,3] <-  data[,3] +  rnorm(n*groups) + fc\n",
        "data[,4] <-  data[,4] +  rnorm(n*groups) + fc\n",
        "data[,5] <-  data[,5] +  rnorm(n*groups) + fc\n",
        "data[,6] <-  data[,6] +  rnorm(n*groups) + fc\n",
        "\n",
        "colnames(data) <- c(\"group\",\"y1\",\"y2\",\"y3\",\"y4\",\"y5\") \n",
        "data <- as.data.frame(data)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets inspect the simulated network:"
      ],
      "metadata": {
        "id": "dGctKblEiGa1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# plot b as a network, note the transpose because qgraph is different then lavaan.\n",
        "qgraph(t(b))"
      ],
      "metadata": {
        "id": "Xl4dMwWHiHIr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5sDhbAggv-um"
      },
      "source": [
        "## Fitting a multi group network SEM.\n",
        "\n",
        "Now we first fit the basic multi group model. In this model we fix the regresisons of the endogeneous variables on eahother across groups.\n",
        "\n",
        "\n",
        "First we define the model in the lavaan SEM syntax (if you aren't familiar see [here](https://lavaan.ugent.be/tutorial/syntax1.html) for details).\n",
        "\n",
        "briefly like in other R formula's `~` represents a regression relation, while `=~` r`epresents a factor loading and `~~` represents a (co)variance.\n",
        "\n",
        "Latameters that are explicity labeled are constrained across groups (like `l1*`) as are further parameters in the `sem()` function call.\n",
        "\n",
        "In the `sem()` function call we also indicate which variable defines group membership.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SyhKk4Zevg7U"
      },
      "outputs": [],
      "source": [
        "model.rigo <- \"\n",
        "  \n",
        "  fc  =~ l1*y1 + l2*y2 + l3*y3 + l4*y4 + l5*y5\n",
        "  f1 =~ y1\n",
        "  f2 =~ y2\n",
        "  f3 =~ y3\n",
        "  f4 =~ y4\n",
        "  f5 =~ y5\n",
        "  \n",
        "  fc ~~ 1*fc\n",
        "  \n",
        "  y1 ~~ a*y1\n",
        "  y2 ~~ b*y2\n",
        "  y3 ~~ c*y3\n",
        "  y4 ~~ d*y4\n",
        "  y5 ~~ e*y5\n",
        "\n",
        "  \n",
        "f1 ~ f2 + f3 + f4 + f5\n",
        "f2 ~ f1 + f3 + f4 + f5\n",
        "f3 ~ f1 + f2 + f4 + f5\n",
        "f4 ~ f1 + f2 + f3 + f5\n",
        "f5 ~ f1 + f2 + f3 + f4\n",
        "\"\n",
        "\n",
        "model.fit.rigo <- sem(model = model.rigo,data = data,group = \"group\",group.equal = c(\"regressions\",\"loadings\"),orthogonal.y = T,orthogonal.x =T)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To confirm the model worked lets compare the simulated and estimated network edges:"
      ],
      "metadata": {
        "id": "g-OfZZqhe8bp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "estimated <- model.fit.rigo@ParTable$est[model.fit.rigo@ParTable$op == \"~\"][1:20]\n",
        "c <- b # get true network\n",
        "diag(c) <- NA # omit diag\n",
        "simulated <- na.omit(as.vector(t(c))) # vectorize\n",
        "\n",
        "plot(estimated,simulated,pch=19) # plot treu vs estimated paths\n",
        "abline(0,1,col=\"red\",lty=\"dashed\")"
      ],
      "metadata": {
        "id": "AOMi5nUce-4k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# relaxing assumptions somewhat\n",
        "\n",
        "It might not be reasonable to constrain error and confounding to be equal across all groups, but if you have sufficient groups, specific (ideally theory driven!) allowences can be made.\n",
        "\n",
        "To illustrate, I (somewhat arbitrarially) release certain factor loadings and error variances. \n",
        "\n",
        "A more systematic strategy would be to use known within group test-restest correlations for indicators to proxy for measurement error and to define per group scaling factors for the error based on these. "
      ],
      "metadata": {
        "id": "ikGhJf6vgROU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.rigo.relax <- \"\n",
        "  \n",
        "  fc  =~ l1*y1 + l2*y2 + l3*y3 + c(l4,l4,l4,l4,l4,l4,l4,l4_8,l4_9,l4_10)*y4 + l5*y5\n",
        "  f1 =~ y1\n",
        "  f2 =~ y2\n",
        "  f3 =~ y3\n",
        "  f4 =~ y4\n",
        "  f5 =~ y5\n",
        "  \n",
        "  fc ~~ 1*fc\n",
        "  \n",
        "  y1 ~~ a*y1\n",
        "  y2 ~~ b*y2\n",
        "  y3 ~~ c(c1,c2,c3,c,c,c,c,c,c,c)*y3\n",
        "  y4 ~~ d*y4\n",
        "  y5 ~~ e*y5\n",
        "\n",
        "  \n",
        "f1 ~ f2 + f3 + f4 + f5\n",
        "f2 ~ f1 + f3 + f4 + f5\n",
        "f3 ~ f1 + f2 + f4 + f5\n",
        "f4 ~ f1 + f2 + f3 + f5\n",
        "f5 ~ f1 + f2 + f3 + f4\n",
        "\"\n",
        "\n",
        "model.fit.rigo.relax <- sem(model = model.rigo.relax,data = data,group = \"group\",group.equal = c(\"regressions\",\"loadings\"),orthogonal.y = T,orthogonal.x =T)\n"
      ],
      "metadata": {
        "id": "85BRsSAygfuI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We again compere the true and simualted rtesults and see pretty decent retrieval."
      ],
      "metadata": {
        "id": "ZQMRixcmg64s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "estimated <- model.fit.rigo.relax@ParTable$est[model.fit.rigo.relax@ParTable$op == \"~\"][1:20]\n",
        "c <- b # get true network\n",
        "diag(c) <- NA # omit diag\n",
        "simulated <- na.omit(as.vector(t(c))) # vectorize\n",
        "\n",
        "plot(estimated,simulated,pch=19) # plot treu vs estimated paths\n",
        "abline(0,1,col=\"red\",lty=\"dashed\")"
      ],
      "metadata": {
        "id": "h_6UniAPggIn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## relaxing the network?\n",
        "\n",
        "You can even relax constraints of specific network paths to allow for heterogeneity between (but not within) groups. Obviously here illustrated in a very naive way by releasing the f5 ~ f4 path for 2 random groups.\n",
        "\n",
        "In emperical applications you'd always prefer to relax and retain paths based on theory, or to explicitly test theory (e.g. if you have all groups split across gender, age, etc you might consider gender and age specific networks)."
      ],
      "metadata": {
        "id": "i3u2Y4sfi6__"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.rigo.relax.further <- \"\n",
        "  \n",
        "  fc  =~ l1*y1 + l2*y2 + l3*y3 + c(l4,l4,l4,l4,l4,l4,l4,l4_8,l4_9,l4_10)*y4 + l5*y5\n",
        "  f1 =~ y1\n",
        "  f2 =~ y2\n",
        "  f3 =~ y3\n",
        "  f4 =~ y4\n",
        "  f5 =~ y5\n",
        "  \n",
        "  fc ~~ 1*fc\n",
        "  \n",
        "  y1 ~~ a*y1\n",
        "  y2 ~~ b*y2\n",
        "  y3 ~~ c(c1,c2,c3,c,c,c,c,c,c,c)*y3\n",
        "  y4 ~~ d*y4\n",
        "  y5 ~~ e*y5\n",
        "\n",
        "  \n",
        "f1 ~ f2 + f3 + f4 + f5\n",
        "f2 ~ f1 + f3 + f4 + f5\n",
        "f3 ~ f1 + f2 + f4 + f5\n",
        "f4 ~ f1 + f2 + f3 + f5\n",
        "f5 ~ f1 + f2 + f3 + c(b54,b54,b54,b54_g4,b54,b54,b54,b54,b54,b54_g10)*f4\n",
        "\"\n",
        "\n",
        "model.fit.rigo.relax.further <- sem(model = model.rigo.relax.further,data = data,group = \"group\",group.equal = c(\"regressions\",\"loadings\"),orthogonal.y = T,orthogonal.x =T)\n"
      ],
      "metadata": {
        "id": "6l5rvzvWi90n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We again compare estimated to simualted and see reasonable concordance."
      ],
      "metadata": {
        "id": "MDcNWh3ojTgw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "estimated <- model.fit.rigo.relax.further@ParTable$est[model.fit.rigo.relax.further@ParTable$op == \"~\"][1:20]\n",
        "c <- b # get true network\n",
        "diag(c) <- NA # omit diag\n",
        "simulated <- na.omit(as.vector(t(c))) # vectorize\n",
        "\n",
        "plot(estimated,simulated,pch=19) # plot treu vs estimated paths\n",
        "abline(0,1,col=\"red\",lty=\"dashed\")"
      ],
      "metadata": {
        "id": "brY6miinjUSD"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOtfgvAHTV4eUQsV87WLUQm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "R",
      "name": "ir"
    },
    "language_info": {
      "name": "R"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}